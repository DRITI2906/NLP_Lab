{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40aff258",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter, defaultdict\n",
    "import random\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ad719f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 1557 sentences.\n",
      "Total tokens for training: 21856\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from collections import defaultdict, Counter\n",
    "with open(\"tokenized.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "all_sentences = [sentence for sentence in data[\"sentences\"]]\n",
    "all_tokens = [token for sentence in data[\"tokens\"] for token in sentence]\n",
    "print(f\"Successfully loaded {len(all_sentences)} sentences.\")\n",
    "print(f\"Total tokens for training: {len(all_tokens)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1849e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly selected 1000 sentences for testing.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random.seed(42) \n",
    "test_sentences = random.sample(all_sentences, 1000)\n",
    "print(f\"Randomly selected {len(test_sentences)} sentences for testing.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbfdeb73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size (V): 8264\n",
      "Pre-computation complete.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "unigram_counts = Counter(all_tokens)\n",
    "bigram_counts = Counter(zip(all_tokens, all_tokens[1:]))\n",
    "\n",
    "V = len(unigram_counts)\n",
    "print(f\"Vocabulary Size (V): {V}\")\n",
    "\n",
    "#Pre-compute T(w)->the number of unique token types that follow each word w\n",
    "#Token Type Smoothing\n",
    "following_types = defaultdict(set)\n",
    "for w1, w2 in bigram_counts:\n",
    "    following_types[w1].add(w2)\n",
    "T = {word: len(types) for word, types in following_types.items()}\n",
    "print(\"Pre-computation complete.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99bdc824",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_add_one_prob(sentence, unigram_counts, bigram_counts, V):\n",
    "    #Add-One (Laplace) smoothing\n",
    "    log_prob = 0.0\n",
    "    for i in range(len(sentence) - 1):\n",
    "        w1, w2 = sentence[i], sentence[i+1]\n",
    "        bigram = (w1, w2)\n",
    "        \n",
    "        # Formula: P(w2 | w1) = (count(w1, w2) + 1) / (count(w1) + V)\n",
    "        numerator = bigram_counts.get(bigram, 0) + 1\n",
    "        denominator = unigram_counts.get(w1, 0) + V\n",
    "        \n",
    "        log_prob += np.log(numerator / denominator)\n",
    "        \n",
    "    return log_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7d55f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_add_k_prob(sentence, unigram_counts, bigram_counts, V, k):\n",
    "    #Add-K smoothing\n",
    "    log_prob = 0.0\n",
    "    for i in range(len(sentence) - 1):\n",
    "        w1, w2 = sentence[i], sentence[i+1]\n",
    "        bigram = (w1, w2)\n",
    "        \n",
    "        # Formula: P(w2 | w1) = (count(w1, w2) + k) / (count(w1) + k*V)\n",
    "        numerator = bigram_counts.get(bigram, 0) + k\n",
    "        denominator = unigram_counts.get(w1, 0) + k * V\n",
    "        \n",
    "        log_prob += np.log(numerator / denominator)\n",
    "        \n",
    "    return log_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8bccb268",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_token_type_prob(sentence, unigram_counts, bigram_counts, T):\n",
    "    #Token Type\" smoothing.\n",
    "    #P(w2 | w1) = (count(w1, w2) + 1) / (count(w1) + T(w1))\n",
    "    #T(w1)->number of unique word types that follow w1.\n",
    "\n",
    "    log_prob = 0.0\n",
    "    for i in range(len(sentence) - 1):\n",
    "        w1, w2 = sentence[i], sentence[i+1]\n",
    "        bigram = (w1, w2)\n",
    "        \n",
    "        # Get count of unique followers for w1, default to V if w1 is unknown\n",
    "        num_following_types = T.get(w1, V)\n",
    "        \n",
    "        numerator = bigram_counts.get(bigram, 0) + 1\n",
    "        denominator = unigram_counts.get(w1, 0) + num_following_types\n",
    "        \n",
    "        # Avoid division by zero if a token somehow has 0 count and 0 followers\n",
    "        if denominator == 0:\n",
    "            continue\n",
    "\n",
    "        log_prob += np.log(numerator / denominator)\n",
    "        \n",
    "    return log_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21792af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_value = 0.1 \n",
    "\n",
    "results = []\n",
    "\n",
    "for sentence in test_sentences:\n",
    "    #sentence to short for bi-gram\n",
    "    if len(sentence) < 2:\n",
    "        continue\n",
    "    \n",
    "    prob_add_one = calculate_add_one_prob(sentence, unigram_counts, bigram_counts, V)\n",
    "    prob_add_k = calculate_add_k_prob(sentence, unigram_counts, bigram_counts, V, k_value)\n",
    "    prob_token_type = calculate_token_type_prob(sentence, unigram_counts, bigram_counts, T)\n",
    "    \n",
    "    results.append({\n",
    "        \"sentence\": \" \".join(sentence),\n",
    "        \"add_one_log_prob\": prob_add_one,\n",
    "        \"add_k_log_prob\": prob_add_k,\n",
    "        \"token_type_log_prob\": prob_token_type\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5641e5c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(A higher log probability, closer to 0, indicates a better fit by the model)\n",
      "\n",
      "Sentence 1: \"સ ં ય ુ ક ્ ત   પ ્ ર સ ્ ત ા વ મ ા ં   મ ા ં ગ   ક ર વ ા મ ા ં   આ વ ી   હ ત ી   ક ે ,   વ ડ ા પ ્ ર ધ ા ન   ન ર ે ન ્ દ ્ ર   મ ો દ ી ન ી   સ ર ક ા ર મ ા ં   લ ો ક ત ા ં ત ્ ર િ ક   અ સ ં મ ત િ ન ે   સ ત ્ ત ા ન ા   જ ો ર ે   દ બ ા વ વ ા મ ા ં   આ વ ી   ર હ ી   છ ે\"\n",
      "Add-One Smoothing Log Prob:      -1199.7360\n",
      "Add-K (k=0.1) Smoothing Log Prob: -1200.7257\n",
      "Token Type Smoothing Log Prob:   -928.5598\n",
      "\n",
      "Sentence 2: \"જ ો   પ ્ ર જ ા   આ ક ્ ર મ ક   બ ન શ ે   અ ન ે   ત ા ળ બ ં ધ ી   સ ુ ધ ી ન ી   ત ૈ ય ા ર ી   દ ર ્ શ ા વ શ ે   ત ો   પ ્ ર જ ા   મ ા ટ ે   આ   ન ા ણ ા   ઉ પ ય ો ગ   ક ર વ ા ન ી   ત સ ્ દ ી   ક દ ા ચ   ન ા છ ુ ટ ક ે   આ   બ ં દ ર ન ે   લ ે વ ા ન ી   ફ ર જ   પ ડ ી   શ ક ે   છ ે\"\n",
      "Add-One Smoothing Log Prob:      -1244.9214\n",
      "Add-K (k=0.1) Smoothing Log Prob: -1246.6235\n",
      "Token Type Smoothing Log Prob:   -982.1496\n",
      "\n",
      "Sentence 3: \"ક ો ઈ   ક ં પ ન ી   ત ે ઓ   સ ં બ ં ધ િ ત   છ ે ,   સ ા ં જ ે   ચ ા   અ ન ે   ર મ ુ જ ી   ઉ ખ ા ણ ા ઓ   એ ક   ક પ   સ ા થ ે   વ ધ ુ   મ જ ા   હ શ ે\"\n",
      "Add-One Smoothing Log Prob:      -658.5029\n",
      "Add-K (k=0.1) Smoothing Log Prob: -659.0763\n",
      "Token Type Smoothing Log Prob:   -559.0992\n",
      "\n",
      "Sentence 4: \"પ ્ ર ધ ા ન મ ં ત ્ ર ી   ન ર ે ન ્ દ ્ ર ભ ા ઈ   મ ો દ ી ન ા   વ ર દ   હ સ ્ ત ે   ર ૂ . ૧ ૧ ૮   ક ર ો ડ ન ા   “ લ ા ઈ ટ   હ ા ઉ સ ”   પ ્ ર ો જ ે ક ્ ટ ન ુ ં   1   જ ા ન ્ ય ુ આ ર ી એ   ઈ - ખ ા ત મ ુ હ ૂ ર ્ ત   ર ા જ ક ો ટ   મ હ ા ન ગ ર પ ા લ િ ક ા   દ ્ વ ા ર ા   ર ૈ ય ા   સ ્ મ ા ર ્ ટ   સ િ ટ ી   એ ર િ ય ા   ખ ા ત ે   ર ૂ\"\n",
      "Add-One Smoothing Log Prob:      -1479.3752\n",
      "Add-K (k=0.1) Smoothing Log Prob: -1480.6442\n",
      "Token Type Smoothing Log Prob:   -1133.4552\n",
      "\n",
      "Sentence 5: \"આ ઈ\"\n",
      "Add-One Smoothing Log Prob:      -9.0525\n",
      "Add-K (k=0.1) Smoothing Log Prob: -9.3078\n",
      "Token Type Smoothing Log Prob:   -6.1738\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"(A higher log probability, closer to 0, indicates a better fit by the model)\\n\")\n",
    "\n",
    "#for first 5 sentences\n",
    "for i in range(5):\n",
    "    res = results[i]\n",
    "    print(f\"Sentence {i+1}: \\\"{res['sentence']}\\\"\")\n",
    "    print(f\"Add-One Smoothing Log Prob:      {res['add_one_log_prob']:.4f}\")\n",
    "    print(f\"Add-K (k={k_value}) Smoothing Log Prob: {res['add_k_log_prob']:.4f}\")\n",
    "    print(f\"Token Type Smoothing Log Prob:   {res['token_type_log_prob']:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['આ', 'વીડિયો', 'જુઓ', 'ઊંઝા', 'માર્કેટયાર્ડ', 'આજથી', 'જુલાઈ', 'સુધી', 'બંધ', 'મિથેનોલ', 'આવ્યો', 'ક્યાંથી', 'આખરે', 'ત્રણ', 'રાજ્યોમાં', 'મળેલ', 'હાર', 'પર', 'કોંગ્રેસ', 'અધ્યક્ષ', 'રાહુલ', 'ગાંધી', 'દ્વારા', 'પ્રથમ', 'પ્રતિક્રિયા', 'આપવામાં', 'આવી', 'છે', 'તેમણે', 'કહ્યું', 'કે', 'ત્રિપુરા', 'નાગાલેન્ડ', 'અને', 'મેઘાલયમાં', 'લોકોના', 'જનાદેશનો', 'સ્વાગત', 'કરીએ', 'છે', 'અને', 'આ', 'ક્ષેત્રના', 'લોકોનો', 'વિશ્વાસ', 'ફરીથી', 'જીતીવા', 'માટે', 'પ્રતિબદ્ધ', 'છીએ']\n"
     ]
    }
   ],
   "source": [
    "print(all_tokens[:50])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
