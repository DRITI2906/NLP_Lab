{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbafe959",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "from collections import defaultdict, Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecee6ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"Sentence\": [\n",
    "        \"Check out https://example.com for more info!\",\n",
    "        \"Order 3 items, get 1 free! Limited offer!!!\",\n",
    "        \"Your package #12345 will arrive tomorrow.\",\n",
    "        \"Win $1000 now, visit http://winbig.com!!!\",\n",
    "        \"Meeting at 3pm, don't forget to bring the files.\",\n",
    "        \"Exclusive deal for you: buy 2, get 1 free!!!\",\n",
    "        \"Download the report from https://reports.com.\",\n",
    "        \"The meeting is starting in 10 minutes.\",\n",
    "        \"Reminder: submit your timesheet by 5pm today.\"\n",
    "    ],\n",
    "    \"Label\": [\n",
    "        \"Inform\", \"Promo\", \"Inform\", \"Promo\",\n",
    "        \"Reminder\", \"Promo\", \"Inform\", \"Reminder\", \"Reminder\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f978118",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "\n",
    "    # Replace URLs with special token\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', ' URL ', text)\n",
    "\n",
    "    # Replace numbers with special token\n",
    "    text = re.sub(r'\\b\\d+(\\.\\d+)?\\b', ' NUMBER ', text)\n",
    "\n",
    "    # Replace punctuation with special token\n",
    "    punct_pattern = f\"[{re.escape(string.punctuation)}]\"\n",
    "    text = re.sub(punct_pattern, ' PUNCT ', text)\n",
    "\n",
    "    # Tokenize (split by spaces)\n",
    "    tokens = text.split()\n",
    "\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d7f8679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           Sentence  \\\n",
      "0      Check out https://example.com for more info!   \n",
      "1       Order 3 items, get 1 free! Limited offer!!!   \n",
      "2         Your package #12345 will arrive tomorrow.   \n",
      "3         Win $1000 now, visit http://winbig.com!!!   \n",
      "4  Meeting at 3pm, don't forget to bring the files.   \n",
      "5      Exclusive deal for you: buy 2, get 1 free!!!   \n",
      "6     Download the report from https://reports.com.   \n",
      "7            The meeting is starting in 10 minutes.   \n",
      "8     Reminder: submit your timesheet by 5pm today.   \n",
      "\n",
      "                                        Preprocessed     Label  \n",
      "0                  check out URL for more info PUNCT    Inform  \n",
      "1  order NUMBER items PUNCT get NUMBER free PUNCT...     Promo  \n",
      "2  your package PUNCT NUMBER will arrive tomorrow...    Inform  \n",
      "3               win PUNCT NUMBER now PUNCT visit URL     Promo  \n",
      "4  meeting at 3pm PUNCT don PUNCT t forget to bri...  Reminder  \n",
      "5  exclusive deal for you PUNCT buy NUMBER PUNCT ...     Promo  \n",
      "6                       download the report from URL    Inform  \n",
      "7    the meeting is starting in NUMBER minutes PUNCT  Reminder  \n",
      "8  reminder PUNCT submit your timesheet by 5pm to...  Reminder  \n"
     ]
    }
   ],
   "source": [
    "df[\"Preprocessed\"] = df[\"Sentence\"].apply(preprocess)\n",
    "print(df[[\"Sentence\", \"Preprocessed\", \"Label\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa825777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TF-IDF Feature Matrix:\n",
      "\n",
      "     3pm    5pm  arrive     at  bring    buy     by  check   deal    don  ...  \\\n",
      "0  0.000  0.000   0.000  0.000  0.000  0.000  0.000  0.429  0.000  0.000  ...   \n",
      "1  0.000  0.000   0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  ...   \n",
      "2  0.000  0.000   0.416  0.000  0.000  0.000  0.000  0.000  0.000  0.000  ...   \n",
      "3  0.000  0.000   0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  ...   \n",
      "4  0.318  0.000   0.000  0.318  0.318  0.000  0.000  0.000  0.000  0.318  ...   \n",
      "5  0.000  0.000   0.000  0.000  0.000  0.289  0.000  0.000  0.289  0.000  ...   \n",
      "6  0.000  0.000   0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  ...   \n",
      "7  0.000  0.000   0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  ...   \n",
      "8  0.000  0.367   0.000  0.000  0.000  0.000  0.367  0.000  0.000  0.000  ...   \n",
      "\n",
      "   timesheet     to  today  tomorrow    url  visit   will    win    you   your  \n",
      "0      0.000  0.000  0.000     0.000  0.315  0.000  0.000  0.000  0.000  0.000  \n",
      "1      0.000  0.000  0.000     0.000  0.000  0.000  0.000  0.000  0.000  0.000  \n",
      "2      0.000  0.000  0.000     0.416  0.000  0.000  0.416  0.000  0.000  0.352  \n",
      "3      0.000  0.000  0.000     0.000  0.343  0.467  0.000  0.467  0.000  0.000  \n",
      "4      0.000  0.318  0.000     0.000  0.000  0.000  0.000  0.000  0.000  0.000  \n",
      "5      0.000  0.000  0.000     0.000  0.000  0.000  0.000  0.000  0.289  0.000  \n",
      "6      0.000  0.000  0.000     0.000  0.364  0.000  0.000  0.000  0.000  0.000  \n",
      "7      0.000  0.000  0.000     0.000  0.000  0.000  0.000  0.000  0.000  0.000  \n",
      "8      0.367  0.000  0.367     0.000  0.000  0.000  0.000  0.000  0.000  0.310  \n",
      "\n",
      "[9 rows x 48 columns]\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(df[\"Preprocessed\"])\n",
    "\n",
    "tfidf_df = pd.DataFrame(\n",
    "    tfidf_matrix.toarray(),\n",
    "    columns=vectorizer.get_feature_names_out()\n",
    ")\n",
    "\n",
    "print(\"\\nTF-IDF Feature Matrix:\\n\")\n",
    "print(tfidf_df.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a8fe8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(text):\n",
    "    return {\n",
    "        \"has_url\": int(\"URL\" in text),\n",
    "        \"has_number\": int(\"NUMBER\" in text),\n",
    "        \"has_punct\": int(\"PUNCT\" in text)\n",
    "    }\n",
    "\n",
    "binary_feats = df[\"Preprocessed\"].apply(extract_features)\n",
    "binary_df = pd.DataFrame(list(binary_feats))\n",
    "df = df.loc[:, ~df.columns.duplicated()]\n",
    "df = pd.concat([df, binary_df], axis=1)\n",
    "df = df.loc[:, ~df.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56848c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bigrams(tokens):\n",
    "    return [(tokens[i], tokens[i+1]) for i in range(len(tokens)-1)]\n",
    "\n",
    "# Build bigram counts per label\n",
    "bigram_counts = defaultdict(Counter)\n",
    "unigram_counts = defaultdict(Counter)\n",
    "labels = df[\"Label\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed0405e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, row in df.iterrows():\n",
    "    tokens = row[\"Preprocessed\"].split()\n",
    "    label = row[\"Label\"]\n",
    "    for bg in get_bigrams(tokens):\n",
    "        bigram_counts[label][bg] += 1\n",
    "    for token in tokens:\n",
    "        unigram_counts[label][token] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "807d9ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set(token for label in labels for token in unigram_counts[label])\n",
    "V = len(vocab)\n",
    "K = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8522ec17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed Test: ['you', 'will', 'get', 'an', 'exclusive', 'offer', 'in', 'the', 'meeting', 'PUNCT']\n"
     ]
    }
   ],
   "source": [
    "test_sentence = \"You will get an exclusive offer in the meeting!\"\n",
    "test_prep = preprocess(test_sentence)\n",
    "tokens = test_prep.split()\n",
    "print(\"Preprocessed Test:\", tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a5c8a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigram_backoff_prob(tokens, label, K=0.3):\n",
    "    \"\"\"\n",
    "    Compute bigram probability with unigram backoff.\n",
    "    \"\"\"\n",
    "    prob = 1.0\n",
    "    V = len(vocab)\n",
    "    \n",
    "    for i in range(len(tokens)):\n",
    "        if i == 0:\n",
    "            # First token: use unigram probability\n",
    "            count_uni = unigram_counts[label][tokens[i]]\n",
    "            total_uni = sum(unigram_counts[label].values())\n",
    "            p = (count_uni + K) / (total_uni + K * V)\n",
    "        else:\n",
    "            bigram = (tokens[i-1], tokens[i])\n",
    "            count_bg = bigram_counts[label][bigram]\n",
    "            count_prev = unigram_counts[label][tokens[i-1]]\n",
    "            \n",
    "            if count_bg > 0:\n",
    "                # Seen bigram\n",
    "                p = (count_bg + K) / (count_prev + K * V)\n",
    "            else:\n",
    "                # Backoff to unigram\n",
    "                count_uni = unigram_counts[label][tokens[i]]\n",
    "                total_uni = sum(unigram_counts[label].values())\n",
    "                p = (count_uni + K) / (total_uni + K * V)\n",
    "                \n",
    "        prob *= p\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f32e9a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_priors = df[\"Label\"].value_counts(normalize=True).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cccedebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_label_backoff(tokens):\n",
    "    scores = {}\n",
    "    for label in labels:\n",
    "        score = np.log(label_priors[label])\n",
    "        score += np.log(bigram_backoff_prob(tokens, label))\n",
    "        scores[label] = score\n",
    "    return max(scores, key=scores.get), scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2bbe2f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentence = \"You will get an exclusive offer in the meeting!\"\n",
    "test_prep = preprocess(test_sentence)\n",
    "tokens = test_prep.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7bc9d832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed Test: ['you', 'will', 'get', 'an', 'exclusive', 'offer', 'in', 'the', 'meeting', 'PUNCT']\n",
      "Predicted Label: Promo\n",
      "Label Scores: {'Inform': np.float64(-43.27516779107038), 'Promo': np.float64(-41.84566543246728), 'Reminder': np.float64(-42.13943206335457)}\n"
     ]
    }
   ],
   "source": [
    "pred_label, label_scores = predict_label_backoff(tokens)\n",
    "print(\"Preprocessed Test:\", tokens)\n",
    "print(\"Predicted Label:\", pred_label)\n",
    "print(\"Label Scores:\", label_scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
